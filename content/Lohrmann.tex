\chapter{Algorithmus mit Warteschlangen-Theorie}

Lohrmann et al. beschreiben in ihrem Paper \cite{lohrmann_elastic_2015} einen Algorithmus, der das Ziel verfolgt, die Latenz der Tupel einer Topologie unter einem, durch den Benutzer bestimmten, Maximalwert zu halten.
Dieses Ziel soll mit einem möglichst geringen Verbrauch von Ressourcen erreicht werden.
Die Latenz eines Tupels bestimmt sich aus der Zeit, welche das Tupel benötigt um von der Quelle zum Konsument zu gelangen.

Dementsprechend ist die Wahl des Pfades für die Latenz des Tupels essentiell, da die sie mindestens die Summe der Latenz aller Operatoren in einem Pfad ist.
Außerdem fließt die Zeit, in der Tupel sich zwischen Operatoren bewegen, in die Latenz des Tupels mit ein.
Einerseits beinhaltet dies die Latenz des Netzwerks, über das die Tupel versendet werden.
Diese Latenz kann jedoch nicht durch reines Skalieren der Operatoren beeinflusst werden, sondern ist von deren Platzierung abhängig.
Im Modell des Algorithmus wird die Netzwerklatenz nicht explizit berücksichtigt.
Der zweite Faktor ist die Zeit, welche zwischen der Ankunft eines Tupels im Zwischenspeicher des Operators und der Bearbeitung des Tupels durch den Operator liegt.
Diese Zeit zwischen Ankunft und Bearbeitung wird in dem Algorithmus durch ein Modell aus der Warteschlangentheorie abgebildet.
Die Dauer, in der sich ein Tupel in der Warteschlange vor der Bearbeitung durch den Operator befindet, wird folgend als Wartezeit bezeichnet.
Der Algorithmus bedient sich der Kingman-Formel aus der Warteschlangen-Theorie um die Wartezeit zu berechnen.
Sie modelliert eine Warteschlange mit einem einzelnen Abnehmer.
Da die genannten Faktoren alle vom gewählten Pfad des Tupels abhängig sind, kann man auch von der Latenz eines Pfades sprechen.

Der Algorithmus von Lohrmann et al. berechnet mit Hilfe der Warteschlangentheorie die Latenz eines Pfades.
Diese Berechnung wird für alle Pfade der Topologie ausgeführt.
Er vergleicht pro Pfad die berechneten Werte mit dem für den Pfad gegebenen Maximalwert für die Latenz.
Der Maximalwert der Latenz des Pfades muss vom Benutzer angegeben werden, bevor der Algorithmus ausgeführt wird.
Der Algorithmus versucht den gegebenen Maximalwert für die Latenz des Pfades mit dem geringsten Ressourcenverbrauch zu erreichen.
Um minimale Ressourcen zu verbrauchen, startet der Algorithmus bei dem minimalen Parallelisierungsgrad für alle Operatoren.
Schrittweise berechnet er dann, bei welchem Operator eine Erhöhung des Parallelisierungsgrades um eins die größte Verringerung der Latenz des Pfades zur Folge hat.
Außerdem bestimmt der Algorithmus den Operator, welcher den zweitgrößten Effekt auf die Latenz des Pfades hat.
Für den Operator mit dem größten Effekt wird dann durch die von Lohrmann et al. definierte Funktion \(P_\Delta\) ein neuer Parallelisierungsgrad bestimmt.
Diese berechnet den neuen Parallelisierungsgrad in Abhängigkeit zum Operator mit dem zweitgrößten Effekt.
So soll verhindert werden, dass der Parallelisierungsgrad eines Operators mehrfach hintereinander um eins erhöht wird.
Stattdessen wird der Parallelisierungsgrad des gewählten Operators von \(P_\Delta\) so weit erhöht, dass in der nächsten Runde ein anderer Operator gewählt wird.
Diese Schritte werden so lange durchgeführt, bis der Pfad eine Latenz unter dem definierten Maximalwert aufweist.

\section{Implementation}

Im Folgenden sollen die Besonderheiten und Abweichungen vom Original in der vorliegenden Implementation des Algorithmus ausführlich diskutiert werden.
Die Implementation des Algorithmus von Lohrmann et al. verwendet das vorgestellte Graph-Modell.

\subsection{Latenz eines Tupels}
Eine weitere Feststellung ist für die Berechnung der Latenz eines einzelnen Tupels notwendig.
Laut Lohrmann et al. wird diese von dem Zeitpunkt an dem das Tupel von der Quelle emittiert wird bis zu dem Zeitpunkt an dem das Tupel an dem Konsument aufgenommen wird berechnet. 
Dabei ist nicht eindeutig definiert, ob die Latenz des Konsument-Operators berücksichtigt wird. 
In der vorliegenden Implementation wird die Latenz des Konsumentes ebenfalls zur Gesamtlatenz des Tupels gezählt.

\subsection{Initialisierung}
Für die fehlerfreie Berechnung des Parallelisierungsgrades ist es notwendig, dass das Modell so initialisiert ist, dass die zwischengespeicherten Messwerte größer als 0 sind.
Ist dies nicht der Fall kann es zu Divisionen durch 0 führen.
Daher wird vor der eigentlichen Ausführung des Algorithmus das Modell auf die korrekte Initialisierung geprüft. 
Falls dies nicht zutrifft, wird eine IllegalStateException geworfen, welche angibt, dass das Modell nicht ordnungsgemäß initialisiert ist.

\subsection{Minimaler Parallelisierungsgrad und Flaschenhals}
Die Wartezeit von Operator \(i\) wird von Lohrmann et. al mit der folgenden Funktion berechnet: \cite{lohrmann_elastic_2015}:
\[W(p_i^\ast) = e \left( \frac{\lambda_i {S}^{2}_{i} p_i}{p_i^\ast-\lambda_i {S}_i p_i}\right)\left(\frac{{c^{2}_{Ai}} + {c^{2}_{Si}}}{2}\right)\]
Der Wert des Koeffizienten \(e\) resultiert aus einer Angleichung der Ergebnisse des Modells an die Messwerte des realen CEP-Systems.
Er wird im nächsten Kapitel gesondert diskutiert.
\(\lambda\) ist die durchschnittliche Tupel-Ankunftsrate pro Millisekunde welche mit \[\frac{1}{Tupel-Ankunftsintervall}\] berechnet wird. 
\({S}\) beschreibt die Bearbeitungsdauer in Millisekunden.
\(p\) ist der aktuelle Parallelisierungsgrad des Operators.
Die aktuellen Messwerte aus dem CEP-System sind für diesen Parallelisierungsgrad gültig.
\(p^\ast\) ist der potentielle neue Parallelisierungsgrad des Operators.
Der Algorithmus versucht die Wartezeit durch das optimieren von \(p^\ast\) so anzupassen, dass die Latenzbeschränkung des Pfades eingehalten wird. Dabei aber möglichst wenig Ressourcen verwendet werden.
Der letzte Teil der Formel berechnet einen Koeffizienten aus den Varianzen der Bearbeitungsdauer und der Tupel-Ankunftsrate.
Essentiell für die folgenden Ausführungen ist vor allem der Nenner \(p_i^\ast-\lambda_i {S}_i p_i\).

Ein wichtiges Detail ist, dass ein negativer Nenner für die Funktion nicht sinnvoll ist.
Da die anderen beiden Koeffizienten immer positiv sind würde ein negativer Nenner im Ergebnis zu einer negativen Wartezeit führen.
Eine negative Wartezeit ist aber real nicht möglich, deswegen ist die Formel für diesen Anwendungsfall ungültig, wenn sie einen negativen Nenner besitzt.
Des Weiteren ist die Funktion offensichtlich ungültig wenn nach der Subtraktion im Nenner eine Null steht.

Um diese Probleme zu verhindern legen Lohrmann et al. fest, dass die Berechnungen des Algorithmus nur gültig sind, wenn in der Topologie keine Flaschenhälse vorhanden sind.
Ein Flaschenhals wird als ein Operator mit einer Auslastung von 100\% oder nahe 100\% definiert.
Um einen Flaschenhals aufzulösen wird im vorgeschlagenen Algorithmus der Parallelisierungsgrad des Operators verdoppelt. Falls die Auslastung höher als eins ist, wird der Parallelisierungsgrad noch mit der momentanen Auslastung multipliziert. Da der Parallelisierungsgrad eine Ganzzahl sein muss, muss das Produkt zu einem Integer umgewandelt werden. In der vorliegenden Implementation werden die Kommastellen nach der Multiplikation abgeschnitten und nicht gerundet. Bei einer Verdoppelung des Parallelisierungsgrades übt die maximale Differenz von 1 keinen starken Einfluss aus und der Code ist leichter zu lesen. Lohrmann et al. treffen selbst keine Aussage zu dieser Problematik.

Jedoch ist die Methode, Flaschenhälse in der Topologie aufzulösen, nicht ausreichend um die zuvor beschriebenen Probleme zu verhindern.
Die Auflösung der Flaschenhälse sorgt nur dafür, dass die Bedingung \( 0 < \lambda S < 1 \) erfüllt ist.
Um einen Nenner > 0 zu erhalten muss aber die Bedingung \(p^\ast > \lambda S p\) erfüllt sein.
Nehmen wir den Grenzwert \(1\) für die Auslastung (\(\lambda S\) an.
Dies bedeutet immer wenn \(p \geq p^\ast\) zutrifft ist der Nenner null oder negativ.
Lässt man die Auslastung gegen den Grenzwert \(0\) gehen, so ist der Nenner unter der Bedingung \(p \gg p^\ast\) null oder negativ.
Wie im ersten Teil dieses Kapitels beschrieben, berechnet der Algorithmus zu Beginn die Wartezeit mit dem minimalen Parallelisierungsgrad.
Wie in Kapitel ******** beschrieben ist es gewöhnlich, dass dieser eins beträgt.
Wir nehmen an der Algorithmus startet mit dem potentiellen Parallelisierungsgrad \(p^\ast\ = 1\).
Der momentan im System aktive Parallelisierungsgrad \(p\) bleibt für einen gesamten Durchlauf des Algorithmus konstant.
Da \(p^\ast = 1\) ist es nicht unwahrscheinlich, dass \(p \gg p^\ast\) zutrifft und somit der Nenner \(\leq 0\) ist.
Dies ist für die Anwendung aber nicht zulässig und stellt deshalb ein Fehler im von Lohrmann et al. vorgestellten Algorithmus dar.
Die Berechnung des Algorithmus darf nicht in allen Fällen mit dem im Modell festegelegten minimalen Parallelisierungsgrad von eins beginnen.
Stattdessen ist die Auswahl des minimalen Parallelisierungsgrades eines Operators wie folgt zu definieren: \(max(p_min, \lambda S p + 1\).
Die Erhöhung um eins ist notwendig um zu Verhindern, dass der Nenner null wird.
Diese Änderung wurde in der vorliegenden Implementation des Algorithmus umgesetzt.

\subsection{Ausnahme bei Flaschenhals mit maximalem Parallelisierungsgrad}
Wie zuvor beschrieben wird beim Auftreten einen Flaschenhalses der Parallelisierungsgrad des Operators verdoppelt. 
Dabei kann es vorkommen, dass der maximale Parallelisierungsgrad eines Operators überschritten wird. 
Die Implementation des Algorithmus wirft in diesen Fall eine Ausnahme, welche besagt dass der Operator trotz maximalem Parallelisierungsgrad ein Flaschenhals ist.
Es wird keine weitere Anpassung unternommen.

\subsection{Ausnahme bei nicht ausreichendem Parallelisierungsgrad}
Nachdem die Flaschenhälse aufgelöst wurden, prüft der Algorithmus, ob es mit der momentanen Konfiguration möglich ist den Grenzwert für die Latenz des Pfades zu erreichen,
Dazu wird die Latenz für den Fall berechnet, dass alle Operatoren bis zum maximalen Parallelisierungsgrad skaliert sind. Ist dies nicht der Fall, werden in der originalen Version des Algorithmus ohne weitere Mitteilung alle Operatoren maximal skaliert. In der vorliegenden Implementation wurde dieses Verhalten geändert, sodass eine IllegalStateException geworfen wird. Diese sagt aus, dass der maximale Parallelisierungsgrad nicht ausreichend ist. Eine Anpassung des Parallelisierungsgrades findet demnach nicht statt.

\subsection{Verhindere Loop durch zu kleinen Parallelisierungsgrad}
Wenn der Algorithmus schrittweise die Parallelisierungsgrade der Operatoren optimiert, wird die Funktion \(P\_\delta\) aufgerufen.
Sie bestimmt den nächsten Parallelisierungsgrad des Operators.
Entgegen der Intention der Funktion, dass in der nächsten Runde des Algorithmus ein anderer Operator gewählt wird, liefert Sie teilweise den aktuellen Parallelisierungsgrad des Operators.
Der Parallelisierungsgrad des gewählten Operators ändert sich dementsprechend nicht.
Dies führt offensichtlich dazu, dass er in der nächsten Runde wieder gewählt wird, da alle Parameter der Warteschlangen-Funktion identisch geblieben sind.
Dieses Verhalten führt zu einer endlosen Schleife im Algorithmus.
Um das Problem zu beheben wird in der Implementation das Ergebnis der Funktion \(P_\Delta\) geprüft.
Sei \(p\) der momentane Parallelisierungsgrad des Operators.
Das Ergebnis der Funktion \(P_\Delta\) ist \(p_Delta\).
Dann bestimmt sich der zukünftige Parallelisierungsgrad des Operators aus dem Maximum \(max(p+1, p_Delta\).

\subsection{Parallelisierungsgrad des letzten Operators}
In einem Spezialfall des Algorithmus wird die von Lohrmann et al. definierte Funktion \(P_w\) verwendet. 
Sie bestimmt den Parallelisierungsgrad des letzten verbleibenden Operators, wenn alle anderen Operatoren bereits maximal skaliert sind.
Allerdings weist diese im von Lohrmann et al. definierten Algorithmus keine Beschränkung durch den maximalen Parallelisierungsgrad des Operators auf. 
Es treten somit Fälle auf, in denen die Funktion einen Parallelisierungsgrade über dem Maximum zurückliefert.
Theoretisch sollte der Maximalwert nicht überschritten werden, denn zu Beginn überprüft der Algorithmus ob der Grenzwert für die Latenz unter maximaler Skalierung erreicht werden kann.
Dass dieser Fall dennoch eintritt hängt mit der im nächsten Kapitel beschriebenen Problematik zusammen.
Um diesen Fehler zu vermeiden wird in dieser Implementation das Ergebnis der Funktion geprüft und auf den maximalen Parallelisierungsgrad gesetzt, falls es diesen übersteigt.

\subsection{Koeffizient e}

Im Folgenden wird der Einfluss des Koeffizienten e auf die Funktion \(P_w\) untersucht.
Die Funktion ist wie folgt definiert:
\[P_w(i, w) = \lceil \frac{a_i}{w} + \lambda_i S_i p_i \rceil \]
\[a_i = \lambda_i S^{2}_{i} p_i \left(\frac{{c^{2}_{Ai}} + {c^{2}_{Si}}}{2}\right)\]

Der Parameter \(i\) bestimmt dabei den Index des Operators. 
Der Parameter \(w\) ist definiert als die für den Operator maximal erlaubte Wartezeit, um den Grenzwert für die Gesamtlatenz für den Pfad nicht zu überschreiten.
Diese ist bekannt, da \(i\) der letzte Operator ist, der noch nicht maximal skaliert ist.
Außerdem folgt aus der initialen Prüfung, dass die maximale Latenz zumindest bei maximaler Parallelisierung erreicht werden kann.

Die Funktion \(P_w\) ist die nach \(p_i^\ast\) umgestellte Variante der Funktion \(W(p_i^\ast\), die die Wartezeit eines Operators abhängig vom Parallelisierungsgrad bestimmt. 
Die umgestellte Formel bestimmt nun den Parallelisierungsgrad eines Operators abhängig von der maximal erlaubten Warteschlangenzeit \(w\). 
Allerdings wurde bei der Umstellung der Formel der Koeffizient \(e\) nicht berücksichtigt oder aus Pw absichtlich entfernt. 

Koeffizient \(e\) beschreibt die prozentuale Abweichung der gemessenen Wartezeit zur berechneten Wartezeit aus der Kingman-Formel. 
Er wird in der Funktion \(W\) benutzt um die Abweichung von Modell und realem System auszugleichen.
\(e\) wird wie folgt berechnet:
\[ e_i = \frac{l_{ji} - obl_{ji}}{Kingman_i}\]

wobei \(l_{ji}\) die Latenz des Kanals zwischen Operator \(i\) und dessen Vorgänger \(j\) beschreibt.
Die Latenz der Stapelverarbeitung am Ausgang von \(j\) wird durch \(obl_{ji}\) repräsentiert.
Ist die Netzwerklatenz in \(l_{ji}\) nicht Berücksichtigt ist die Differenz der beiden Latenzen ist die effektive Wartezeit eines Tupels im realen System.

Durch die fehlende Berücksichtigung von e kann der aus \(P_w\) resultierende Parallelisierungsgrad stark von dem in \(W\) angenommenen Wert abweichen. 
Angenommen die maximale Warteschlangendauer \(w = 1 \) wird in der Funktion \(W\) durch den Parallelisierungsgrad \(p^\ast = 1\) erfüllt. 
Es gilt also \(W(1)=1\).
Gleichzeitig nehmen wir an, dass \(e = 0,5\) beträgt. 
Der gemessene Wartezeit beträgt also nur 50\% des berechneten Wartezeit \(W(1) = 2 * 0,5\).
Der Koeffizient passt den berechneten Wert entsprechend an.
Berechnet man nun \(Pw\) für \(w = 1\) wird ein Parallelisierungsgrad von \(2\) zurückgeliefert, da dieser nicht um den Faktor \(e = 0,5\) angeglichen wurde. 
Der aus Pw resultierende Parallelisierungsgrad verschwendet also Ressourcen wenn angenommen wird, dass \(W(p)\) korrekt ist und der Parallelisierungsrad \(p=1\) genügt um \(w = 1\) zu erfüllen.

Nehmen wir nun an, dass \(p=1\) der maximale Parallelisierungsgrad eines Operators ist.
Um zu prüfen ob der Operator die maximal erlaubte Warteschlangenzeit \(w=1\) erfüllen kann, wird mit \(W(1) = 1\) geprüft ob er mit maximaler Auslastung diesen Wert erreicht . 
\(Pw\) bestimmt nun die tatsächliche Ausprägung des Parallelisierungsgrades und liefert den Wert \(2\), der den maximalen Parallelisierungsgrad überschreitet.

Drastischer ist das Problem für den Fall, dass der Faktor \(e > 1\) ist. 
Dann würde der gemessene Wert größer als der berechnete Wert sein. 
Nehmen wir an \(e = 1.5, W(3)=1}\) und \(W(3) = (2/3) * 1.5\) sowie \(w=1\). 
Das Ergebnis von \(W\) ergibt, dass sich die maximale Warteschlangenzeit durch den Parallelisierungsgrad von 3 erfüllen lässt. 
Wird nun der Parallelisierungsgrad durch \(Pw\) berechnet resultiert daraus \(2\). 
Somit würde durch den geringeren Parallelisierungsgrad der Maximalwert für die Latenz des Pfades verletzt.

Um diesem Problem entgegen zu wirken, wird in der Implementation des Algorithmus das Ergebnis von \(P_w\) mit dem Koeffizienten \(e\) multipliziert.

