\chapter{Elastizität von CEP-Systemen}

In diesem Kapitel wird der Begriff Elastizität für CEP-Systeme und die Notwendigkeit dieser Eigenschaft erläutert.
Es werden Konzepte, mit denen ein CEP-System den Datendurchsatz erhöhen kann, und deren Einsatzmöglichkeiten vorgestellt.
Anschließend werden einige Algorithmen aus der Literatur untersucht, die die Elastizität eines CEP-Systems steuern können.
Zwei der vorgestellten Algorithmen werden gewählt und im Verlauf dieser Arbeit implementiert und evaluiert.

CEP-Systeme ermöglichen es dem Anwender Datenströme zu verarbeiten.
Der Unterschied zu reinen Datenstrom verarbeitenden Systemen liegt darin, dass die Operationen oft komplexer sind und einen Zustand besitzen  \cite{carbone_towards_2013}.
Deshalb verwenden CEP-Systeme oft SQL-ähnliche Abfragesprachen, die auf dem Datenstrom ausgeführt werden \cite{carbone_towards_2013}.
Wie der Datenstrom verarbeitet wird ist durch eine sogenannte Topologie beschrieben.
Die Topologie wird durch Operatoren, die eine Funktion auf den Daten durchführen, und deren Abfolge definiert.

Das Ziel von CEP-Systemen ist die zuverlässige Verarbeitung von Daten in Realzeit.
Eine der acht Anforderungen an Datenstromverarbeitung in Realzeit ist die Skalierbarkeit des Systems \cite{stonebraker_8_2005}, da die zu bearbeitenden Datenströme Schwankungen unterliegen.
Um diese Schwankungen abzufangen, muss sich das CEP-System, an den ankommenden Datenstrom anpassen.
Ist die Kapazität des Systems zu klein, dann verfallen die Daten oder können nicht mehr unter Realzeit entsprechenden Bedingungen abgearbeitet werden.
Ein Ansatz besteht darin das System für die maximal auftretende Spitze der Schwankung zu konfigurieren, sofern diese bekannt ist.
Dies verursacht jedoch Kosten für Ressourcen, die gegebenenfalls über große Zeiträume nicht genutzt werden.
Durch Cloud-Computing ist es aber möglich Ressourcen nur dann zu mieten, wenn Sie tatsächlich benötigt werden.
Es ist daher ökonomisch sinnvoll einen Ansatz zu verfolgen, der die Ressourcen des CEP-Systems so anpasst, dass die Verarbeitung in Realzeit garantiert ist aber die Kosten minimal sind.
Die Eigenschaft, dass ein System nach Bedarf dynamisch und automatisiert Ressourcen hinzufügen oder entfernen kann und damit auf den aktuellen Arbeitsaufwand reagiert, wird als Elastizität bezeichnet \cite{herbst_elasticity_nodate}.
Daraus folgt, dass ein CEP-System, das die Verarbeitung von Daten in Realzeit zum Ziel hat, nur öknomisch sinnvoll eingesetzt werden kann, wenn es elastisch ist.

Neben dem öknonomischen Aspekt gibt es eine weitere technische Erfordernis für die Elastizität von CEP-Systemen.
Die genauen Schwankungen und somit auch die Auslastungsspitzen können nicht exakt bestimmt werden.
Außerdem kann sich die durchschnittliche Menge der Daten im Datenstrom ändern.
Somit ist eine Anpassung des CEP-Systems zumindest in größeren Zeitabständen notwendig.
Ein CEP-System, das für eine Anpassung an einen eintreffenden Datenstrom abgeschaltet werden muss, kann währenddessen keine Daten mehr entgegennehmen.
Daher verfallen diese oder müssen durch einen Zwischenspeicher aufgefangen werden.
Beide Methoden verfehlen das Ziel einer konstanten Verarbeitung in Realzeit.
Deshalb muss ein CEP-System, das Daten zuverlässig in Realzeit verarbeiten soll, elastisch sein.

\section{Parallelisierung von Operatoren}

Um ein CEP-System an einen anfallenden Arbeitsaufwand anzupassen, muss es skaliert werden.
Eine triviale Möglichkeit die Leistung eines CEP-Systems zu verbessern besteht darin die Rechenleistung oder den Speicher zu erhöhen.
Dieser Vorgang wird auch vertikales Skalieren genannt und ist erfolgreich, wenn die hinzugefügte Kapazität ausgeschöft werden kann.
Jedoch stößt diese Methode an eine Grenze, wenn der physische Rechner keinen Platz für weitere Kapazitäten besitzt.
Um diese Grenze zu umgehen, kann ein System horizontal skaliert werden.
Bei dieser Variante wird die Last eines einzelnen Rechner auf weitere andere Rechner verteilt.
Das horizontale Skalieren ist eine wichtige Vorgehensweise um Anwendungen im Cloud-Umfeld zu skalieren, da so einfach neue Rechenkapazität hinzugebucht werden kann.
In der Regel bietet nur horizontales Skalieren die notwenidge Flexibilität für ein elastisches System.

Horizontales Skalieren erfordert jedoch, dass das CEP-System es erlaubt Tätigkeiten gleichzeitig auf mehreren Rechnern auszuführen.
Um die Ressourcengewinnung durch horizontaes Skalieren zu nutzen, müssen die Operatoren einer Topologie parallelisiert werden.
Die parallelisierten Teile des Operators können dann auf unterschiedlichen Rechnern ablaufen.
Für die Parallelisierung stehen drei Optionen zur Verfügung \cite{de_assuncao_distributed_2017}:

\begin{itemize}
\item{Parallelisierung durch Fließbandverarbeitung: Operatoren werden dadurch parallelisiert, dass ihre Funktion auf mehrere Operatoren aufgeteilt wird.
Diese Operatoren werden hintereinander in der Topologie angeordnet.
Jeder Operator der Reihe kann dann jeweils ein Tupel zur gleichen Zeit bearbeiten.
Dies erfordert offensichtlich, dass die Funktionalität eines Operators bearbeitet wird und aufgeteilt werden kann.
Dieses Erfordernis stellt auch die Limitierung des Verfahren dar, da ein Operator nicht beliebig oft geteilt werden kann.
Um Elastizität zu erreichen ist diese Vorgehensweise nicht ausreichend, da sie limitiert ist und die Funktionen des Operators für den Skaliervorgang verändert werden müssen.}

\item{Parallele Funktionen: Operatoren werden dadurch parallelisiert, dass auf dem gleichen Tupel unterschiedliche Funktionen parallel ausgeführt werden.
Die Operatoren befinden sich dabei nicht hintereinander sondern werden nebeneinander abgearbeitet.
Jedes Tupel wird zu jedem der parallel arbeitenden Operatoren gesendet.
Dieses Vorgehen erfordert, dass die Funktionen der Operatoren es erlauben unabhängig voneinander durchgeführt zu werden.
Dieses Verfahren wird ebenfalls dadurch limitiert, dass ein Operator nicht in beliebig viele nebenläufige Funktionen aufgeteilt werden kann.
Zudem bauen in CEP-Systemen die von Operatoren versendeten Ergebnisse aufeinander auf, weshalb diese Methode ebenfalls ungenügend ist.}

\item{Parallelisierung des Datenstroms: Bei dieser Form der Parallelisierung wird der Datenstrom, den ein Operator verarbeiten muss, aufgeteilt.
Dafür werden mehrere Instanzen des Operators erzeugt, die die identische Funktion ausführen.
Die Anzahl der Instanzen ist dabei gleich der Anzahl der geteilten Datenströme und wird als Parallelisierungsgrad des Operators bezeichnet.
Jede Instanz bekommt dabei einen anderen Ausschnitt des Datenstroms zur Verarbeitung zugewiesen.}

\end{itemize}

Die Parallelisierung des Datenstroms ist sehr effektiv, da die Funktion des Operators für den Skaliervorgang weitestgehend unbekannt sein kann und nicht verändert werden muss.
Allerdings ist das Aufteilen des Datenstroms schwerer umzusetzen als die beiden anderen Varianten.
Diese beiden Gründe (Komplexität und Effektivität) sorgen dafür, dass diese Art der Parallelisierung in der Forschung am meisten untersucht wird.
Sie bietet das größte Potential, da sie weniger limitiert ist als die anderen beiden Verfahren, gibt aber auf folgende Problemstellungen auf:

\begin{itemize}
\item{Die Höhe des Parallelisierungsgrades muss bestimmt werden.}
\item{Die Aufteilung des Datenstroms muss definiert werden.}
\item{Falls ein Operator einen Zustand besitzt, muss dieser über alle Instanzen gültig sein.}
\end{itemize}

Durch die Parallelisierung darf das Ergebnis nicht anders ausfallen, als wenn es durch eine sequentielle Abfolge der Operators berechnet worden wäre.
Dieses Eigenschaft wird auch als ''safety'' des Operators bezeichnet \cite{gedik_elastic_2014}.
Um ''safety'' eines Operators zu erreichen ist es essentiell die Aufteilung des Datenstroms und die Verteilung des Zustandes zu betrachten.
In der Forschung gibt es viele Arbeiten, die sich mit dieser Problematik auseinandersetzen.
Einige dieser Arbeiten werden in Kapitel zwei genannt.
Die vorliegende Arbeit beschäftigt sich mit der Wahl des Parallelisierungsgrades eines Operators.

\section{Bestimmung des Parallelisierungsgrades}

Das Ziel eines optimalen Parallelisierungsgrades ist, dass das CEP-System die gestellten Anforderungen mit möglichst wenig Ressourcenverbrauch erfüllen kann.
Um die optimalen Parallelisierungsgrade für die Operatoren einer Topologie zu finden, sind in der Forschung einige Algorithmen vorgestellt worden.
Diese Algorithmen verwenden Messwerte, die vom CEP-System bereitgestellt werden, um Berechnungen durchzuführen.
Sinnvollerweise werden die Algorithmen in Cloud-Umgebungen angewandt, da dort Ressourcen zum benötigen Zeitpunkt hinzu gebucht oder abbestellt werden können.
Ist diese Elastizität für die Ressourcen nicht vorhanden, ist die Optimierung des Parallelisierungsgrades nicht effektiv.
Da bei der Parallelisierung des Datenstroms der Operator oft als Blackbox angenommen wird, können viele Algorithmen aus dem Bereich der reinen Datenstromverarbeitung auf ein CEP-System angewendet werden.

Einige der Algorithmen verwenden Ansätze, die rein auf gemessene Überschreitung eines Grenzwertes reagieren.
Ein sehr simpler Algorithmus wurde von Vogel et al. vorgestellt \cite{vogel_autonomic_nodate}.
Der Algorithmus prüft ob der Grenzwert für die Latenz eines Operators überschritten wird.
Ist dies der Fall wird der Parallelisierungsgrad um eine benutzerdefinierte Schrittweite erhöht.
Ist die gemessene Latenz niederer als ein Minimalwert, wird in der gleichen Schrittweite zurück skaliert.

Heinze et al. \cite{heinze_auto-scaling_2014} implementieren zwei verschiedene Grenzwert-basierte Algorithmen.
Der lokale Grenzwert-Ansatz skaliert auf Basis der Grenzwerte für Unter-Auslastung beziehungsweise Überlastung eines Rechners. 
Dabei gibt es nach einer Skalierung eine Zeitperiode, in der der Rechner nicht mehr überprüft wird.
Um häufige Änderungen zu verhindern wird erst skaliert, wenn der Grenzwert mehrfach überschritten wurde.
Beim globalen Grenzwert-Ansatz wird, anstatt der Auslastung eines einzelnen Rechners, die durchschnittliche Auslastung der gesamten Topologie betrachtet.
Der Algorithmus skaliert sobald Grenzwerte überschritten werden. 
Später haben die Autoren den bestehenden Ansatz verbessert, indem sie die Grenzwerte automatisiert über die Optimierung einer Kostenfunktion festgelegen \cite{heinze_online_2015}.

Gedik et al. \cite{gedik_elastic_2014} verwenden hingegen einen Ansatz bei dem der Grenzwert nicht für die gemessene Auslastung des Operators definiert wird.
Sie definieren einen Grenzwert, der beschreibt wie oft der Operator ankommende Tupel nicht aufnehmen konnte.
Wird der gesetzte Grenzwert überschritten, wird dies als Stauung erkannt.
Außerdem messen sie den Durchsatz eines Operators und skalieren ihn nach oben, wenn eine Stauung auftritt aber nur wenn die Skalierung einen positiven Effekt auf den Durchsatz hat.
Operatoren werden hingegen nach unten skaliert, wenn keine Stauung auftritt und auf dem darunter liegenden Parallelisierungsgrad noch keine Stauung gemessen wurde.
Die Parallelität des Operators wird pro Schritt um eins verändert.

In ihrem Paper stellen Liu und Buyya \cite{liu_performance-oriented_2017} einen Algorithmus vor, der ein Profil der Operatoren anlegt. 
Das Profil speichert die CPU-Dauer für Bearbeitung und Serialisierung je Tupel und den Speicher, der jeweils für ein Tupel benötigt wird.
Mit der Anzahl momentan ankommender Tupel und dem Profil kann der Ressourcenverbrauch des Operators bestimmt werden.
Außerdem werden über die CPU-Dauer für Serialisierung Operatoren berücksichtigt, die auf dem selben Rechner liegen, da diese dann null ist.
Liegen viele Operatoren auf dem selben Rechner wird insgesamt weniger CPU-Last erzeugt und somit kann auch der Parallelisierungsgrad kleiner ausfallen.
Der Parallelisierungsgrad wird über Grenzwerte für die Parameter CPU für Bearbeitungsdauer, CPU für Serialisierung und RAM-Verbrauch berechnet.
Immer wenn der Gesamtverbrauch des Operators einen der Grenzwerte überschreitet, wird er so lange aufgeteilt bis der Grenzwert eingehalten wird.

Hidalgo et al. \cite{hidalgo_self-adaptive_2017} verwenden ebenfalls einen Grenzwert-basierten Ansatz der die Auslastung des Operators begrenzt.
Sie stellen dazu einen Algorithmus vor, der kurzzeitig auf Schwankungen reagiert.
Allerdings wird zusätzlich noch eine weitere Variante verwendet, die den Parallelisierungsgrad auf Basis von Vorhersagen der ankommenden Tupel berechnet.
Diese Vorhersagen werden mithilfe einer Markov-Kette berechnet.

Andere Ansätze wiederum beruhen ausschließlich auf Vorhersagen für die Menge von Tupeln und der Bearbeitungslatenz.
Diese Ansätze versuchen das System präventiv zu skalieren, wenn eine zukünftige Änderung des Arbeitsaufkommens vorhergesagt wird.
So stellen Kombi et al. \cite{kombi_preventive_2017} einen Ansatz vor, bei dem die Auslastung des Operators vorhergesagt wird.
Dazu bestimmen die Autoren die Auslastung über die zu erwartende Anzahl ankommender Tupel und der Latenz für die Verarbeitung eines Tupels.
Die Latenz zur Verarbeitung wird dabei als konstant angenommen.
Außerdem verwendet der Algorithmus zusätzlich eine Vorhersage der Ausgangstupel des Vorgänger-Operators.
Mit Hilfe der Ausgangstupel kann der Wert für ankommende Tupel beim betrachteten Operator korrigiert werden.
Der Operator wird für den höheren Wert aus beiden Vorhersagen skaliert.

Einen anderen Algorithmus der auf Vorhersage basiert schlagen Zacheilas et al. vor \cite{zacheilas_elastic_2015}.
Die Arbeit bezieht sich als eine der wenigen direkt auf CEP-Systeme.
Zukünftige Messwerte werden über eine Regression mittels Gauss-Prozessen berechnet.
Die Vorhersage bestimmt die Anzahl eingehender und ausgehender Tupel eines Operators zu zukünftigen Zeitpunkten.
Aus diesen beiden Werten bestimmen die Autoren die Anzahl Tupel, die vom Operator nicht verarbeitet werden können.
Die nicht verarbeiteten Tupel sind eine Variable für die Kostenfunktion aus der ein Graph mit möglichen zukünftigen Zustandsübergängen aufgebaut wird.
Der Operator wird anhand der Zustandsübergänge des kürzesten Pfades durch den Graphen skaliert.

Eine weitere Gruppe von Algorithmen benutzt das Modell der Warteschlangen-Theorie um das Verhalten von Tupeln vor einem Operator zu beschreiben.
In der Arbeit von Mayer et al. \cite{mayer_predictable_2015} wird ein Ansatz mit Warteschlangen-Theorie präsentiert.
Die Arbeit bezieht sich ebenfalls auf CEP-Systeme.
Die Autoren verfolgen das Ziel, die Warteschlange von Tupeln vor einen Operator unter einem benutzerdefinierten Grenzwert zu halten.
Um die Länge der Warteschlange zu bestimmen wird ein mathematisches Modell aus der Warteschlangetheorie verwendet.
Dazu werden die benötigten Werte für das Modell gemessen und mithilfe der Methoden der Zeitreihenanalyse vorhergesagt.
Die Autoren berechnen mit den vorhergesagten Messwerten und dem Profil des Operators die Wahrscheinlichkeit, dass die Warteschlange kürzer oder gleichlang wie der maximale Grenzwert ist.
Liegt diese Wahrscheinlichkeit über einem benutzerdefinierten Grenzwert, wird der Parallelisierungsgrad so lange angepasst, bis der Grenzwert erreicht wird.

Ein weiterer präventiver Ansatz mit dem Modell der Warteschlangen-Theorie wurde von Matteis et al. vorgeschlagen \cite{matteis_elastic_2017}.
Für Ihr Modell messen die Autoren die Rate aller ankommenden Tupel sowie die durchschnittliche Verarbeitungsdauer eines Operators.
Anschließend wird eine Vorhersage basierend auf der Zeitreihe der gemessenen Werte durchgeführt. 
Die Autoren nennen den gleitenden Durchschnitt als möglichen Ansatz, legen aber kein spezielles Vorhersagemodell fest. 
Mit der Vorhersage kann die zukünftige Antwortzeit eines Operators berechnet werden.
Sie ist die Summe aus durchschnittlicher Bearbeitungsdauer und der Zeit, für die sich ein Event in der Warteschlange des Operators befindet.
Für die Bestimmung des Parallelisierungsgrades wird eine Kostenfunktion optimiert, die abhängig vom Parallelisierungsgrad und der Antwortzeit ist.
Diese berücksichtigt die Kosten durch Ressourcenverbrauch, Kosten für das Skalieren und die Kosten für Verletzung der maximal festgelegten Antwortzeit eines Operators. 

Ein weiterer Algorithmus mit Warteschlangen-Theorie wurde von Lohrmann et al. vorgeschlagen \cite{lohrmann_elastic_2015}.
Das Ziel des Algorithmus besteht darin die Latenzen für die Bearbeitung eines Tupels durch die gesamte Topologie einzuhalten.
Dazu wird ein benutzerdefinierter Grenzwert festgelegt.
Mit den im System erfassten Messwerten berechnet der Algorithmus reaktiv mit Hilfe der Warteschlangen-Theorie die Gesamtlatenz des Tupels.
Der Parallelisierungsgrad der Operatoren in der Topologie wird Schrittweise erhöht, bis die summierte Gesamtlatenz unter dem Maximalwert liegt.

Wie zuvor beschrieben kann die Elastizität eines CEP-Systems nur in einer Cloud-Umgebung sinnvoll genutzt werden.
Deshalb gibt es auch Algorithmen, die die Bereitstellung von Cloud-Ressourcen berücksichtigen.
Ein Algorithmus dieser Art schlagen Hochreiner et al. vor.
Für die Elastizität des Systems berücksichtigen die Autoren die Zeiteinheit der Rechnungsstellung um bereits bezahlte Ressourcen nicht vorzeitig zurück zu geben.
Ressourcen mit kürzerer Laufzeit werden früher zurückgegeben falls nach unten skaliert wird.
Der Algorithmus skaliert die Operatoren, sobald die benutzerdefinierten Grenzwerte für Überlastung oder Unter-Auslastung überschritten werden.

Für die genauere Betrachtung in dieser Arbeit wurde je ein Algorithmus der präventiv und einen der reaktiv agiert ausgewählt.
Zudem sollten die Algorithmen verschiedene Modelle besitzen.
Im weiteren Verlauf der Arbeit wird zum einen der Algorithmus von Lohrmann et al. als rein reaktiver Ansatz mit dem Warteschlangen-Modell implementiert und betrachtet.
Dessen Ziel ist die konstante Einhaltung der Latenz eines Tupels.
Der Ansatz unterscheidet sich außerdem von vielen anderen Algorithmen dadurch, dass die Gesamtlatenz eines Tupels in der Topologie betrachtet wird.
Außerdem wurde der Algorithmus von Zacheilas et al. als rein präventiver Algorithmus gewählt.
Dieser wählt den Parallelisierungsgrad durch die Optimierung einer Kostenfunktion über einen Graphen.
Die exakte Funktionsweise und die vorliegende Implementierung der Algorithmen sind in den Kapiteln sieben und acht beschrieben.




