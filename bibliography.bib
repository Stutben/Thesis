% Encoding: UTF-8

%%%
%
%Beim Erstellen der Bibtex-Datei wird empfohlen darauf zu achten, dass die DOI aufgeführt wird.
%
%%%

@article{stonebraker_8_2005,
	title = {The 8 {Requirements} of {Real}-time {Stream} {Processing}},
	volume = {34},
	issn = {0163-5808},
	url = {http://doi.acm.org/10.1145/1107499.1107504},
	doi = {10.1145/1107499.1107504},
	abstract = {Applications that require real-time processing of high-volume data steams are pushing the limits of traditional data processing infrastructures. These stream-based applications include market feed processing and electronic trading on Wall Street, network and infrastructure monitoring, fraud detection, and command and control in military environments. Furthermore, as the "sea change" caused by cheap micro-sensor technology takes hold, we expect to see everything of material significance on the planet get "sensor-tagged" and report its state or location in real time. This sensorization of the real world will lead to a "green field" of novel monitoring and control applications with high-volume and low-latency processing requirements.Recently, several technologies have emerged---including off-the-shelf stream processing engines---specifically to address the challenges of processing high-volume, real-time data without requiring the use of custom code. At the same time, some existing software technologies, such as main memory DBMSs and rule engines, are also being "repurposed" by marketing departments to address these applications.In this paper, we outline eight requirements that a system software should meet to excel at a variety of real-time stream processing applications. Our goal is to provide high-level guidance to information technologists so that they will know what to look for when evaluation alternative stream processing solutions. As such, this paper serves a purpose comparable to the requirements papers in relational DBMSs and on-line analytical processing. We also briefly review alternative system software technologies in the context of our requirements.The paper attempts to be vendor neutral, so no specific commercial products are mentioned.},
	number = {4},
	urldate = {2018-04-27},
	journal = {SIGMOD Rec.},
	author = {Stonebraker, Michael and Çetintemel, Uǧur and Zdonik, Stan},
	month = dec,
	year = {2005},
	keywords = {Basic, Theorie},
	pages = {42--47},
	file = {ACM Full Text PDF:C\:\\Users\\Beni\\Zotero\\storage\\N8QSQ8RR\\Stonebraker et al. - 2005 - The 8 Requirements of Real-time Stream Processing.pdf:application/pdf}
}

@article{vogel_autonomic_nodate,
	title = {Autonomic and {Latency}-{Aware} {Degree} of {Parallelism} {Management} in {SPar}},
	abstract = {Stream processing applications became a representative workload in current computing systems. A signiﬁcant part of these applications demands parallelism to increase performance. However, programmers are often facing a trade-oﬀ between coding productivity and performance when introducing parallelism. SPar was created for balancing this trade-oﬀ to the application programmers by using the C++11 attributes’ annotation mechanism. In SPar and other programming frameworks for stream processing applications, the manual deﬁnition of the number of replicas to be used for the stream operators is a challenge. In addition to that, low latency is required by several stream processing applications. We noted that explicit latency requirements are poorly considered on the state-of-the-art parallel programming frameworks. Since there is a direct relationship between the number of replicas and the latency of the application, in this work we propose an autonomic and adaptive strategy to choose the proper number of replicas in SPar to address latency constraints. We experimentally evaluated our implemented strategy and demonstrated its eﬀectiveness on a real-world application, demonstrating that our adaptive strategy can provide higher abstraction levels while automatically managing the latency.},
	language = {en},
	author = {Vogel, Adriano and Griebler, Dalvan and Sensi, Daniele De and Danelutto, Marco and Fernandes, Luiz Gustavo},
	pages = {12},
	file = {Vogel et al. - Autonomic and Latency-Aware Degree of Parallelism .pdf:C\:\\Users\\Beni\\Zotero\\storage\\ELJP3QHK\\Vogel et al. - Autonomic and Latency-Aware Degree of Parallelism .pdf:application/pdf}
}

@article{goggel_vergleich_2018,
	title = {Vergleich und {Analyse} geläufiger {CEP} {Systeme}},
	copyright = {info:eu-repo/semantics/openAccess},
	url = {http://elib.uni-stuttgart.de/handle/11682/9615},
	doi = {http://dx.doi.org/10.18419/opus-9598},
	abstract = {Heutzutage werden komplexe Anfragen in Echtzeit auf großen Datenmengen ausgeführt. Immer mehr Daten fallen an und das Interesse diese in Echtzeit zu analysieren steigt. Die Performance eines Systems ist ein enorm wichtiger Faktor. Momentan setzen besonders große Firmen wie Google, Amazon und Netflix CEP-Systeme ein, um effizient Nutzerdaten zu analysieren und dem Anwender daraufhin Empfehlungen vorzuschlagen. Die aktuell verfügbaren CEP-Frameworks verhalten sich jeweils unterschiedlich und haben unterschiedliche Ziele.
Bisherige Auswertungen fokussieren sich nur auf jeweils ein Framework und optimieren dieses. In meiner Arbeit werden verschiedene Frameworks gegenübergestellt und untersucht, wie flexibel sie angesteuert werden können und inwieweit sie zur Laufzeit detaillierte statistische Werte liefern können. Des Weiteren wird eine API entworfen, die ermöglicht verschiedene CEP Frameworks anzusprechen und somit standardisiert den Parallelisierungsgrad und somit die Performance eines CEP-Systems zu verbessern. Durch die Standardisierung ist es auch möglich die Performance bei CEP-Systemen mit mehrere CEP-Frameworks zu regeln.
Im ersten Teil der Ausarbeitung werden verschiedene Frameworks verglichen und untersucht inwieweit sich diese für eine zentrale Ansteuerung eignen. Im zweiten Teil wird ein Interface definiert und zum Evaluieren beispielhaft ein Adapter für ein CEP-Framework erstellt.},
	language = {de},
	urldate = {2018-10-14},
	author = {Göggel, Jonathan},
	year = {2018},
	file = {Full Text PDF:C\:\\Users\\Beni\\Zotero\\storage\\XAIVXNI5\\Göggel - 2018 - Vergleich und Analyse geläufiger CEP Systeme.pdf:application/pdf;Snapshot:C\:\\Users\\Beni\\Zotero\\storage\\ZGIW26W6\\9615.html:text/html}
}

@inproceedings{zacheilas_dynamic_2016,
	address = {New York, NY},
	title = {Dynamic {Load} {Balancing} {Techniques} for {Distributed} {Complex} {Event} {Processing} {Systems}},
	isbn = {978-3-319-39576-0},
	language = {en},
	booktitle = {Distributed applications and interoperable systems},
	publisher = {Springer Berlin Heidelberg},
	author = {Zacheilas, Nikos and Zygouras, Nikolas and Panagiotou, Nikolaos and {Kalogeraki, Vana} and {Gunopulos, Dimitrios}},
	year = {2016},
	file = {2016 - Distributed applications and interoperable systems.pdf:C\:\\Users\\Beni\\Zotero\\storage\\ER79EW5C\\2016 - Distributed applications and interoperable systems.pdf:application/pdf}
}

@article{herbst_elasticity_nodate,
	title = {Elasticity in {Cloud} {Computing}: {What} {It} {Is}, and {What} {It} {Is} {Not}},
	abstract = {Originating from the ﬁeld of physics and economics, the term elasticity is nowadays heavily used in the context of cloud computing. In this context, elasticity is commonly understood as the ability of a system to automatically provision and deprovision computing resources on demand as workloads change. However, elasticity still lacks a precise deﬁnition as well as representative metrics coupled with a benchmarking methodology to enable comparability of systems. Existing deﬁnitions of elasticity are largely inconsistent and unspeciﬁc, which leads to confusion in the use of the term and its differentiation from related terms such as scalability and efﬁciency; the proposed measurement methodologies do not provide means to quantify elasticity without mixing it with efﬁciency or scalability aspects. In this short paper, we propose a precise deﬁnition of elasticity and analyze its core properties and requirements explicitly distinguishing from related terms such as scalability and efﬁciency. Furthermore, we present a set of appropriate elasticity metrics and sketch a new elasticity tailored benchmarking methodology addressing the special requirements on workload design and calibration.},
	language = {en},
	author = {Herbst, Nikolas Roman and Kounev, Samuel and Reussner, Ralf},
	pages = {6},
	file = {Herbst et al. - Elasticity in Cloud Computing What It Is, and Wha.pdf:C\:\\Users\\Beni\\Zotero\\storage\\IFAHS5K8\\Herbst et al. - Elasticity in Cloud Computing What It Is, and Wha.pdf:application/pdf}
}

@article{hidalgo_self-adaptive_2017,
	title = {Self-adaptive processing graph with operator fission for elastic stream processing},
	volume = {127},
	issn = {0164-1212},
	url = {http://www.sciencedirect.com/science/article/pii/S0164121216300796},
	doi = {10.1016/j.jss.2016.06.010},
	abstract = {Nowadays, information generated by the Internet interactions is growing exponentially, creating massive and continuous flows of events from the most diverse sources. These interactions contain valuable information for domains such as government, commerce, and banks, among others. Extracting information in near real-time from such data requires powerful processing tools to cope with the high-velocity and the high-volume stream of events. Specially designed distributed processing engines build a graph-based topology of a static number of processing operators creating bottlenecks and load balance problems when processing dynamic flows of events. In this work we propose a self-adaptive processing graph that provides elasticity and scalability by automatically increasing or decreasing the number of processing operators to improve performance and resource utilization of the system. Our solution uses a model that monitors, analyzes and changes the graph topology with a control algorithm that is both reactive and proactive to the flow of events. We have evaluated our solution with three stream processing applications and results show that our model can adapt the graph topology when receiving events at high rate with sudden peaks, producing very low costs of memory and CPU usage.},
	urldate = {2018-06-06},
	journal = {Journal of Systems and Software},
	author = {Hidalgo, Nicolas and Wladdimiro, Daniel and Rosas, Erika},
	month = may,
	year = {2017},
	keywords = {S4, Henriette, nicht so gut, Zeitreihen Vorhersage},
	pages = {205--216},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Beni\\Zotero\\storage\\CTBVXCZN\\Hidalgo et al. - 2017 - Self-adaptive processing graph with operator fissi.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Beni\\Zotero\\storage\\YA74G6HU\\S0164121216300796.html:text/html;Summary - Self adapting processing Graph.pdf:C\:\\Users\\Beni\\Zotero\\storage\\W8UXKFSA\\Summary - Self adapting processing Graph.pdf:application/pdf}
}

@article{mayer_predictable_2015,
	title = {Predictable {Low}-{Latency} {Event} {Detection} {With} {Parallel} {Complex} {Event} {Processing}},
	volume = {2},
	issn = {2327-4662},
	doi = {10.1109/JIOT.2015.2397316},
	abstract = {The tremendous number of sensors and smart objects being deployed in the Internet of Things (IoT) pose the potential for IT systems to detect and react to live-situations. For using this hidden potential, complex event processing (CEP) systems offer means to efficiently detect event patterns (complex events) in the sensor streams and therefore, help in realizing a “distributed intelligence” in the IoT. With the increasing number of data sources and the increasing volume at which data is produced, parallelization of event detection is crucial to limit the time events need to be buffered before they actually can be processed. In this paper, we propose a pattern-sensitive partitioning model for data streams that is capable of achieving a high degree of parallelism in detecting event patterns, which formerly could only consistently be detected in a sequential manner or at a low parallelization degree. Moreover, we propose methods to dynamically adapt the parallelization degree to limit the buffering imposed on event detection in the presence of dynamic changes to the workload. Extensive evaluations of the system behavior show that the proposed partitioning model allows for a high degree of parallelism and that the proposed adaptation methods are able to meet a buffering limit for event detection under high and dynamic workloads.},
	number = {4},
	journal = {IEEE Internet of Things Journal},
	author = {Mayer, R. and Koldehofe, B. and Rothermel, K.},
	month = aug,
	year = {2015},
	keywords = {parallel processing, Internet of Things, quality of service, Adaptation models, buffering limit, Complex event processing (CEP), data parallelization, data streams, Delays, dynamic workloads, Event detection, event pattern detection, Intelligent sensors, IoT, IT systems, Monitoring, parallel complex event processing, pattern-sensitive partitioning model, predictable low-latency event detection, self-adaptation, stream processing},
	pages = {274--286},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Beni\\Zotero\\storage\\H2RRN52Y\\7024105.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Beni\\Zotero\\storage\\FDJJJ7HJ\\Mayer et al. - 2015 - Predictable Low-Latency Event Detection With Paral.pdf:application/pdf}
}


@inproceedings{shah_flux:_2003,
	title = {Flux: an adaptive partitioning operator for continuous query systems},
	shorttitle = {Flux},
	doi = {10.1109/ICDE.2003.1260779},
	abstract = {The long-running nature of continuous queries poses new scalability challenges for dataflow processing. CQ systems execute pipelined dataflows that may be shared across multiple queries. The scalability of these dataflows is limited by their constituent, stateful operators - e.g. windowed joins or grouping operators. To scale such operators, a natural solution is to partition them across a shared-nothing platform. But in the CQ context, traditional, static techniques for partitioned parallelism can exhibit detrimental imbalances as workload and runtime conditions evolve. Long-running CQ dataflows must continue to function robustly in the face of these imbalances. To address this challenge, we introduce a dataflow operator called flux that encapsulates adaptive state partitioning and dataflow routing. Flux is placed between producer-consumer stages in a dataflow pipeline to repartition stateful operators while the pipeline is still executing. We present the flux architecture, along with repartitioning policies that can be used for CQ operators under shifting processing and memory loads. We show that the flux mechanism and these policies can provide several factors improvement in throughput and orders of magnitude improvement in average latency over the static case.},
	booktitle = {Proceedings 19th {International} {Conference} on {Data} {Engineering} ({Cat}. {No}.03CH37405)},
	author = {Shah, M. A. and Hellerstein, J. M. and Chandrasekaran, Sirish and Franklin, M. J.},
	month = mar,
	year = {2003},
	keywords = {Basic, tbr, Theorie},
	pages = {25--36},
	file = {Shah et al. - 2003 - Flux an adaptive partitioning operator for contin.pdf:C\:\\Users\\Beni\\Zotero\\storage\\ZLNBFQW4\\Shah et al. - 2003 - Flux an adaptive partitioning operator for contin.pdf:application/pdf}
}

@inproceedings{matteis_elastic_2017,
	title = {Elastic {Scaling} for {Distributed} {Latency}-{Sensitive} {Data} {Stream} {Operators}},
	doi = {10.1109/PDP.2017.31},
	abstract = {High-volume data streams are straining the limits of stream processing frameworks which need advanced parallel processing capabilities to withstand the actual incoming bandwidth. Parallel processing must be synergically integrated with elastic features in order dynamically scale the amount of utilized resources by accomplishing the Quality of Service goals in a cost-effective manner. This paper proposes a control-theoretic strategy to drive the elastic behavior of latency-sensitive streaming operators in distributed environments. The strategy takes scaling decisions in advance by relying on a predictive model-based approach. Our ideas have been experimentally evaluated on a cluster using a real-world streaming application fed by synthetic and real datasets. The results show that our approach takes the strictly necessary reconfigurations while providing reduced resource consumption. Furthermore, it allows the operator to meet desired average latency requirements with a significant reduction in the experienced latency jitter.},
	booktitle = {2017 25th {Euromicro} {International} {Conference} on {Parallel}, {Distributed} and {Network}-based {Processing} ({PDP})},
	author = {Matteis, T. d and Mencagli, G.},
	month = mar,
	year = {2017},
	keywords = {Queueing, Survey Henriette, gut, Zeitreihen Vorhersage, Skalierkosten, Fokus: Operator, Regelungstechnik},
	pages = {61--68},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Beni\\Zotero\\storage\\ZQZWJTAE\\7912626.html:text/html;Summary - Elastic Scaling for Distributed Latency-Sensitive.pdf:C\:\\Users\\Beni\\Zotero\\storage\\SUQFJPJ6\\Summary - Elastic Scaling for Distributed Latency-Sensitive.pdf:application/pdf;Unbenannt.pdf:C\:\\Users\\Beni\\Zotero\\storage\\HIVSQMJU\\Unbenannt.pdf:application/pdf}
}

@inproceedings{de_matteis_keep_2016,
	title = {Keep calm and react with foresight: strategies for low-latency and energy-efficient elastic data stream processing},
	isbn = {978-1-4503-4092-2},
	shorttitle = {Keep calm and react with foresight},
	url = {http://dl.acm.org/citation.cfm?doid=2851141.2851148},
	doi = {10.1145/2851141.2851148},
	abstract = {This paper addresses the problem of designing scaling strategies for elastic data stream processing. Elasticity allows applications to rapidly change their conﬁguration on-the-ﬂy (e.g., the amount of used resources) in response to dynamic workload ﬂuctuations. In this work we face this problem by adopting the Model Predictive Control technique, a control-theoretic method aimed at ﬁnding the optimal application conﬁguration along a limited prediction horizon in the future by solving an online optimization problem. Our control strategies are designed to address latency constraints, using Queueing Theory models, and energy consumption by changing the number of used cores and the CPU frequency through the Dynamic Voltage and Frequency Scaling (DVFS) support available in the modern multicore CPUs. The proactive capabilities, in addition to the latency- and energy-awareness, represent the novel features of our approach. To validate our methodology, we develop a thorough set of experiments on a high-frequency trading application. The results demonstrate the high-degree of ﬂexibility and conﬁgurability of our approach, and show the effectiveness of our elastic scaling strategies compared with existing state-of-the-art techniques used in similar scenarios.},
	language = {en},
	urldate = {2018-06-06},
	publisher = {ACM Press},
	author = {De Matteis, Tiziano and Mencagli, Gabriele},
	year = {2016},
	keywords = {Fokus: Operator, nicht so gut, Queueing, Regelungstechnik, Skalierkosten, Survey Henriette, Zeitreihen Vorhersage},
	pages = {1--12},
	file = {De Matteis und Mencagli - 2016 - Keep calm and react with foresight strategies for.pdf:C\:\\Users\\Beni\\Zotero\\storage\\356BN377\\De Matteis und Mencagli - 2016 - Keep calm and react with foresight strategies for.pdf:application/pdf;Summary - Keep calm and react.pdf:C\:\\Users\\Beni\\Zotero\\storage\\DKQZTCKX\\Summary - Keep calm and react.pdf:application/pdf}
}

@inproceedings{castro_fernandez_integrating_2013,
	address = {New York, NY, USA},
	series = {{SIGMOD} '13},
	title = {Integrating {Scale} out and {Fault} {Tolerance} in {Stream} {Processing} {Using} {Operator} {State} {Management}},
	isbn = {978-1-4503-2037-5},
	url = {http://doi.acm.org/10.1145/2463676.2465282},
	doi = {10.1145/2463676.2465282},
	abstract = {As users of "big data" applications expect fresh results, we witness a new breed of stream processing systems (SPS) that are designed to scale to large numbers of cloud-hosted machines. Such systems face new challenges: (i) to benefit from the "pay-as-you-go" model of cloud computing, they must scale out on demand, acquiring additional virtual machines (VMs) and parallelising operators when the workload increases; (ii) failures are common with deployments on hundreds of VMs-systems must be fault-tolerant with fast recovery times, yet low per-machine overheads. An open question is how to achieve these two goals when stream queries include stateful operators, which must be scaled out and recovered without affecting query results. Our key idea is to expose internal operator state explicitly to the SPS through a set of state management primitives. Based on them, we describe an integrated approach for dynamic scale out and recovery of stateful operators. Externalised operator state is checkpointed periodically by the SPS and backed up to upstream VMs. The SPS identifies individual operator bottlenecks and automatically scales them out by allocating new VMs and partitioning the checkpointed state. At any point, failed operators are recovered by restoring checkpointed state on a new VM and replaying unprocessed tuples. We evaluate this approach with the Linear Road Benchmark on the Amazon EC2 cloud platform and show that it can scale automatically to a load factor of L=350 with 50 VMs, while recovering quickly from failures.},
	urldate = {2018-06-06},
	booktitle = {Proceedings of the 2013 {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Castro Fernandez, Raul and Migliavacca, Matteo and Kalyvianaki, Evangelia and Pietzuch, Peter},
	year = {2013},
	keywords = {fault tolerance, scalability, stateful stream processing},
	pages = {725--736},
	file = {ACM Full Text PDF:C\:\\Users\\Beni\\Zotero\\storage\\CFGZRL3N\\Castro Fernandez et al. - 2013 - Integrating Scale out and Fault Tolerance in Strea.pdf:application/pdf}
}

@inproceedings{heinze_online_2015,
	address = {New York, NY, USA},
	series = {{SoCC} '15},
	title = {Online {Parameter} {Optimization} for {Elastic} {Data} {Stream} {Processing}},
	isbn = {978-1-4503-3651-2},
	url = {http://doi.acm.org/10.1145/2806777.2806847},
	doi = {10.1145/2806777.2806847},
	abstract = {Elastic scaling allows data stream processing systems to dynamically scale in and out to react to workload changes. As a consequence, unexpected load peaks can be handled and the extent of the overprovisioning can be reduced. However, the strategies used for elastic scaling of such systems need to be tuned manually by the user. This is an error prone and cumbersome task, because it requires a detailed knowledge of the underlying system and workload characteristics. In addition, the resulting quality of service for a specific scaling strategy is unknown a priori and can be measured only during runtime. In this paper we present an elastic scaling data stream processing prototype, which allows to trade off monetary cost against the offered quality of service. To that end, we use an online parameter optimization, which minimizes the monetary cost for the user. Using our prototype a user is able to specify the expected quality of service as an input to the optimization, which automatically detects significant changes of the workload pattern and adjusts the elastic scaling strategy based on the current workload characteristics. Our prototype is able to reduce the costs for three real-world use cases by 19\% compared to a naive parameter setting and by 10\% compared to a manually tuned system. In contrast to state of the art solutions, our system provides a stable and good trade-off between monetary cost and quality of service.},
	urldate = {2018-06-06},
	booktitle = {Proceedings of the {Sixth} {ACM} {Symposium} on {Cloud} {Computing}},
	publisher = {ACM},
	author = {Heinze, Thomas and Roediger, Lars and Meister, Andreas and Ji, Yuanzhen and Jerzak, Zbigniew and Fetzer, Christof},
	year = {2015},
	keywords = {elasticity, distributed data stream processing, load balancing, parameter optimization},
	pages = {276--287},
	file = {ACM Full Text PDF:C\:\\Users\\Beni\\Zotero\\storage\\QPPFUPKV\\Heinze et al. - 2015 - Online Parameter Optimization for Elastic Data Str.pdf:application/pdf}
}

@article{liu_performance-oriented_2017,
	title = {Performance-{Oriented} {Deployment} of {Streaming} {Applications} on {Cloud}},
	issn = {2332-7790},
	url = {http://ieeexplore.ieee.org/document/7962193/},
	doi = {10.1109/TBDATA.2017.2720622},
	abstract = {Performance of streaming applications are signiﬁcantly impacted by the deployment decisions made at infrastructure level, i.e., number and conﬁguration of resources allocated for each functional unit of the application. The current deployment practices are mostly platform-oriented, meaning that the deployment conﬁguration is tuned to a static resource-set environment and thus is inﬂexible to use in cloud with an on-demand resource pool. In this paper, we propose P-Deployer, a deployment framework that enables streaming applications to run on IaaS clouds with satisfactory performance and minimal resource consumption. It achieves performance-oriented, cost-efﬁcient and automated deployment by holistically optimizing the decisions of operator parallelization, resource provisioning, and task mapping. Using a Monitor-Analyze-Plan-Execute (MAPE) architecture, P-Deployer iteratively builds the connection between performance outcome and resource consumption through task proﬁling and models the deployment problem as a bin-packing variant. Extensive experiments using both synthetic and real-world streaming applications have shown the correctness and scalability of our approach, and demonstrated its superiority compared to platform-oriented methods in terms of resource cost.},
	language = {en},
	urldate = {2018-04-18},
	journal = {IEEE Transactions on Big Data},
	author = {Liu, Xunyun and Buyya, Rajkumar},
	year = {2017},
	pages = {1--1},
	file = {Liu und Buyya - 2017 - Performance-Oriented Deployment of Streaming Appli.pdf:C\:\\Users\\Beni\\Zotero\\storage\\45WFURUK\\Liu und Buyya - 2017 - Performance-Oriented Deployment of Streaming Appli.pdf:application/pdf}
}

@inproceedings{heinze_auto-scaling_2014,
	title = {Auto-scaling techniques for elastic data stream processing},
	doi = {10.1109/ICDEW.2014.6818344},
	abstract = {An elastic data stream processing system is able to handle changes in workload by dynamically scaling out and scaling in. This allows for handling of unexpected load spikes without the need for constant overprovisioning. One of the major challenges for an elastic system is to find the right point in time to scale in or to scale out. Finding such a point is difficult as it depends on constantly changing workload and system characteristics. In this paper we investigate the application of different auto-scaling techniques for solving this problem. Specifically: (1) we formulate basic requirements for an auto-scaling technique used in an elastic data stream processing system (2) we use the formulated requirements to select the best auto scaling techniques and (3) we perform evaluation of the selected auto scaling techniques using the real world data. Our experiments show that the auto scaling techniques used in existing elastic data stream processing systems are performing worse than the strategies used in our work.},
	booktitle = {2014 {IEEE} 30th {International} {Conference} on {Data} {Engineering} {Workshops}},
	author = {Heinze, T. and Pappalardo, V. and Jerzak, Z. and Fetzer, C.},
	month = mar,
	year = {2014},
	pages = {296--302},
	file = {Heinze et al. - 2014 - Auto-scaling techniques for elastic data stream pr.pdf:C\:\\Users\\Beni\\Zotero\\storage\\95R5Y34M\\Heinze et al. - 2014 - Auto-scaling techniques for elastic data stream pr.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\Beni\\Zotero\\storage\\CFR7XALK\\6818344.html:text/html}
}

@article{gedik_elastic_2014,
	title = {Elastic {Scaling} for {Data} {Stream} {Processing}},
	volume = {25},
	issn = {1045-9219},
	url = {http://ieeexplore.ieee.org/document/6678504/},
	doi = {10.1109/TPDS.2013.295},
	abstract = {This article addresses the profitability problem associated with auto-parallelization of general-purpose distributed data stream processing applications. Auto-parallelization involves locating regions in the application’s data flow graph that can be replicated at run-time to apply data partitioning, in order to achieve scale. In order to make auto-parallelization effective in practice, the profitability question needs to be answered: How many parallel channels provide the best throughput? The answer to this question changes depending on the workload dynamics and resource availability at run-time. In this article, we propose an elastic auto-parallelization solution that can dynamically adjust the number of channels used to achieve high throughput without unnecessarily wasting resources. Most importantly, our solution can handle partitioned stateful operators via run-time state migration, which is fully transparent to the application developers. We provide an implementation and evaluation of the system on an industrial-strength data stream processing platform to validate our solution.},
	language = {en},
	number = {6},
	urldate = {2018-04-27},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Gedik, Bugra and Schneider, Scott and Hirzel, Martin and Wu, Kun-Lung},
	month = jun,
	year = {2014},
	keywords = {Basic, tbr, Theorie},
	pages = {1447--1463},
	file = {Gedik et al. - 2014 - Elastic Scaling for Data Stream Processing.pdf:C\:\\Users\\Beni\\Zotero\\storage\\AIHQVEG5\\Gedik et al. - 2014 - Elastic Scaling for Data Stream Processing.pdf:application/pdf}
}

@inproceedings{lohrmann_elastic_2015,
	title = {Elastic {Stream} {Processing} with {Latency} {Guarantees}},
	isbn = {978-1-4673-7214-5},
	url = {http://ieeexplore.ieee.org/document/7164926/},
	doi = {10.1109/ICDCS.2015.48},
	abstract = {Many Big Data applications in science and industry have arisen, that require large amounts of streamed or event data to be analyzed with low latency. This paper presents a reactive strategy to enforce latency guarantees in data ﬂows running on scalable Stream Processing Engines (SPEs), while minimizing resource consumption. We introduce a model for estimating the latency of a data ﬂow, when the degrees of parallelism of the tasks within are changed. We describe how to continuously measure the necessary performance metrics for the model, and how it can be used to enforce latency guarantees, by determining appropriate scaling actions at runtime. Therefore, it leverages the elasticity inherent to common cloud technology and cluster resource management systems. We have implemented our strategy as part of the Nephele SPE. To showcase the effectiveness of our approach, we provide an experimental evaluation on a large commodity cluster, using both a synthetic workload as well as an application performing real-time sentiment analysis on real-world social media data.},
	language = {en},
	urldate = {2018-04-18},
	publisher = {IEEE},
	author = {Lohrmann, Bjorn and Janacik, Peter and Kao, Odej},
	month = jun,
	year = {2015},
	pages = {399--410},
	file = {Lohrmann et al. - 2015 - Elastic Stream Processing with Latency Guarantees.pdf:C\:\\Users\\Beni\\Zotero\\storage\\85S2Q37E\\Lohrmann et al. - 2015 - Elastic Stream Processing with Latency Guarantees.pdf:application/pdf}
}

@inproceedings{kombi_preventive_2017,
	title = {A {Preventive} {Auto}-{Parallelization} {Approach} for {Elastic} {Stream} {Processing}},
	doi = {10.1109/ICDCS.2017.253},
	abstract = {Nowadays, more and more sources (connected devices, social networks, etc.) emit real-time data with fluctuating rates over time. Existing distributed stream processing engines (SPE) have to resolve a difficult problem: deliver results satisfying end-users in terms of quality and latency without over-consuming resources. This paper focuses on parallelization of operators to adapt their throughput to their input rate. We suggest an approach which prevents operator congestion in order to limit degradation of results quality. This approach relies on an automatic and dynamic adaptation of resource consumption for each continuous query. This solution takes advantage of i) a metric estimating the activity level of operators in the near future ii) the AUTOSCALE approach which evaluates the need to modify parallelism degrees at local and global scope iii) an integration into the Apache Storm solution. We show performance tests comparing our approach to the native solution of this SPE.},
	booktitle = {2017 {IEEE} 37th {International} {Conference} on {Distributed} {Computing} {Systems} ({ICDCS})},
	author = {Kombi, R. K. and Lumineau, N. and Lamarre, P.},
	month = jun,
	year = {2017},
	keywords = {Storm, Survey Henriette, gut, Nachfolger Operatoren berücksichtigt, Zeitreihen Vorhersage},
	pages = {1532--1542},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Beni\\Zotero\\storage\\K4QEH4ZW\\7980091.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Beni\\Zotero\\storage\\NIVNJND4\\Kombi et al. - 2017 - A Preventive Auto-Parallelization Approach for Ela.pdf:application/pdf;Summary - A Preventive Auto Parallelization.pdf:C\:\\Users\\Beni\\Zotero\\storage\\HLYZFXET\\Summary - A Preventive Auto Parallelization.pdf:application/pdf}
}

@article{lohrmann_nephele_2014,
	title = {Nephele streaming: stream processing under {QoS} constraints at scale},
	volume = {17},
	issn = {1386-7857, 1573-7543},
	shorttitle = {Nephele streaming},
	url = {http://link.springer.com/10.1007/s10586-013-0281-8},
	doi = {10.1007/s10586-013-0281-8},
	abstract = {The ability to process large numbers of continuous data streams in a near-real-time fashion has become a crucial prerequisite for many scientiﬁc and industrial use cases in recent years. While the individual data streams are usually trivial to process, their aggregated data volumes easily exceed the scalability of traditional stream processing systems.},
	language = {en},
	number = {1},
	urldate = {2018-04-23},
	journal = {Cluster Computing},
	author = {Lohrmann, Björn and Warneke, Daniel and Kao, Odej},
	month = mar,
	year = {2014},
	keywords = {tbr},
	pages = {61--78},
	file = {Lohrmann et al. - 2014 - Nephele streaming stream processing under QoS con.pdf:C\:\\Users\\Beni\\Zotero\\storage\\58J3DKCU\\Lohrmann et al. - 2014 - Nephele streaming stream processing under QoS con.pdf:application/pdf}
}

@misc{noauthor_heron_nodate,
	title = {Heron {Metrics}},
	url = {https://apache.github.io/incubator-heron/docs/operators/heron-tracker-api/#topologies_metrics}
}

@inproceedings{zacheilas_elastic_2015,
	title = {Elastic complex event processing exploiting prediction},
	isbn = {978-1-4799-9926-2},
	url = {http://ieeexplore.ieee.org/document/7363758/},
	doi = {10.1109/BigData.2015.7363758},
	urldate = {2018-06-06},
	publisher = {IEEE},
	author = {Zacheilas, Nikos and Kalogeraki, Vana and Zygouras, Nikolas and Panagiotou, Nikolaos and Gunopulos, Dimitrios},
	month = oct,
	year = {2015},
	pages = {213--222},
	file = {Zacheilas et al. - 2015 - Elastic complex event processing exploiting predic.pdf:C\:\\Users\\Beni\\Zotero\\storage\\M5Q6J3T8\\Zacheilas et al. - 2015 - Elastic complex event processing exploiting predic.pdf:application/pdf}
}

@inproceedings{carbone_towards_2013,
	address = {Prague, Czech Republic},
	title = {Towards {Highly} {Available} {Complex} {Event} {Processing} {Deployments} in the {Cloud}},
	isbn = {978-1-4799-2010-5},
	url = {http://ieeexplore.ieee.org/document/6658116/},
	doi = {10.1109/NGMAST.2013.35},
	abstract = {Recent advances in distributed computing have made it possible to achieve high availability on traditional systems and thus serve them as reliable services. For several ofﬂine computational applications, such as ﬁne grained batch processing, their parallel nature in addition to weak consistency requirements allowed a more trivial transition. On the other hand, on-line processing systems such as Complex Event Processing (CEP) still maintain a monolithic architecture, being able to offer high expressiveness and vertical scalability at the expense of low distribution. Despite attempts to design dedicated distributed CEP systems there is potential for existing systems to beneﬁt from a sustainable cloud deployment. In this work we address the main challenges of providing such a CEP service with a focus on reliability, since it is the most crucial aspect of that transition. Our approach targets low average detection latency and sustainability by leveraging event delegation mechanisms present on existing stream execution platforms. It also introduces redundancy and transactional logging to provide improved fault tolerance and partial recovery. Our performance analysis illustrates the beneﬁts of our approach and shows acceptable performance costs for on-line CEP exhibited by the fault tolerance mechanisms we introduced.},
	language = {en},
	urldate = {2018-10-12},
	booktitle = {2013 {Seventh} {International} {Conference} on {Next} {Generation} {Mobile} {Apps}, {Services} and {Technologies}},
	publisher = {IEEE},
	author = {Carbone, Paris and Vandikas, Konstantinos and Zaloshnja, Farjola},
	month = sep,
	year = {2013},
	pages = {153--158},
	file = {Carbone et al. - 2013 - Towards Highly Available Complex Event Processing .pdf:C\:\\Users\\Beni\\Zotero\\storage\\I6K7M9I2\\Carbone et al. - 2013 - Towards Highly Available Complex Event Processing .pdf:application/pdf}
}

@article{akidau_millwheel:_2013,
	title = {{MillWheel}: {Fault}-tolerant {Stream} {Processing} at {Internet} {Scale}},
	volume = {6},
	issn = {2150-8097},
	shorttitle = {{MillWheel}},
	url = {http://dx.doi.org/10.14778/2536222.2536229},
	doi = {10.14778/2536222.2536229},
	abstract = {MillWheel is a framework for building low-latency data-processing applications that is widely used at Google. Users specify a directed computation graph and application code for individual nodes, and the system manages persistent state and the continuous flow of records, all within the envelope of the framework's fault-tolerance guarantees. This paper describes MillWheel's programming model as well as its implementation. The case study of a continuous anomaly detector in use at Google serves to motivate how many of MillWheel's features are used. MillWheel's programming model provides a notion of logical time, making it simple to write time-based aggregations. MillWheel was designed from the outset with fault tolerance and scalability in mind. In practice, we find that MillWheel's unique combination of scalability, fault tolerance, and a versatile programming model lends itself to a wide variety of problems at Google.},
	number = {11},
	urldate = {2018-06-06},
	journal = {Proc. VLDB Endow.},
	author = {Akidau, Tyler and Balikov, Alex and Bekiroğlu, Kaya and Chernyak, Slava and Haberman, Josh and Lax, Reuven and McVeety, Sam and Mills, Daniel and Nordstrom, Paul and Whittle, Sam},
	month = aug,
	year = {2013},
	pages = {1033--1044},
	file = {ACM Full Text PDF:C\:\\Users\\Beni\\Zotero\\storage\\WZYGG3VM\\Akidau et al. - 2013 - MillWheel Fault-tolerant Stream Processing at Int.pdf:application/pdf}
}

@inproceedings{wu_high-performance_2006,
	title = {High-performance complex event processing over streams},
	isbn = {978-1-59593-434-5},
	url = {http://portal.acm.org/citation.cfm?doid=1142473.1142520},
	doi = {10.1145/1142473.1142520},
	abstract = {In this paper, we present the design, implementation, and evaluation of a system that executes complex event queries over real-time streams of RFID readings encoded as events. These complex event queries filter and correlate events to match specific patterns, and transform the relevant events into new composite events for the use of external monitoring applications. Stream-based execution of these queries enables time-critical actions to be taken in environments such as supply chain management, surveillance and facility management, healthcare, etc. We first propose a complex event language that significantly extends existing event languages to meet the needs of a range of RFID-enabled monitoring applications. We then describe a query plan-based approach to efficiently implementing this language. Our approach uses native operators to efficiently handle query-defined sequences, which are a key component of complex event processing, and pipelines such sequences to subsequent operators that are built by leveraging relational techniques. We also develop a large suite of optimization techniques to address challenges such as large sliding windows and intermediate result sizes. We demonstrate the effectiveness of our approach through a detailed performance analysis of our prototype implementation as well as through a comparison to a state-of-the-art stream processor.},
	language = {en},
	urldate = {2018-04-27},
	publisher = {ACM Press},
	author = {Wu, Eugene and Diao, Yanlei and Rizvi, Shariq},
	year = {2006},
	keywords = {tbr, Implementation},
	pages = {407},
	file = {Wu et al. - 2006 - High-performance complex event processing over str.pdf:C\:\\Users\\Beni\\Zotero\\storage\\7CSHDRE4\\Wu et al. - 2006 - High-performance complex event processing over str.pdf:application/pdf}
}

@article{de_assuncao_distributed_2017,
	title = {Distributed {Data} {Stream} {Processing} and {Edge} {Computing}: {A} {Survey} on {Resource} {Elasticity} and {Future} {Directions}},
	shorttitle = {Distributed {Data} {Stream} {Processing} and {Edge} {Computing}},
	url = {http://arxiv.org/abs/1709.01363},
	abstract = {Under several emerging application scenarios, such as in smart cities, operational monitoring of large infrastructure, wearable assistance, and Internet of Things, continuous data streams must be processed under very short delays. Several solutions, including multiple software engines, have been developed for processing unbounded data streams in a scalable and eﬃcient manner. More recently, architecture has been proposed to use edge computing for data stream processing. This paper surveys state of the art on stream processing engines and mechanisms for exploiting resource elasticity features of cloud computing in stream processing. Resource elasticity allows for an application or service to scale out/in according to ﬂuctuating demands. Although such features have been extensively investigated for enterprise applications, stream processing poses challenges on achieving elastic systems that can make eﬃcient resource management decisions based on current load. Elasticity becomes even more challenging in highly distributed environments comprising edge and cloud computing resources. This work examines some of these challenges and discusses solutions proposed in the literature to address them.},
	language = {en},
	urldate = {2018-10-12},
	journal = {arXiv:1709.01363 [cs]},
	author = {de Assuncao, Marcos Dias and Veith, Alexandre da Silva and Buyya, Rajkumar},
	month = sep,
	year = {2017},
	note = {arXiv: 1709.01363},
	keywords = {C.2.4, Computer Science - Distributed, Parallel, and Cluster Computing, H.3.4},
	file = {de Assuncao et al. - 2017 - Distributed Data Stream Processing and Edge Comput.pdf:C\:\\Users\\Beni\\Zotero\\storage\\E479NXSH\\de Assuncao et al. - 2017 - Distributed Data Stream Processing and Edge Comput.pdf:application/pdf}
}

@inproceedings{kulkarni_twitter_2015,
	address = {New York, NY, USA},
	series = {{SIGMOD} '15},
	title = {Twitter {Heron}: {Stream} {Processing} at {Scale}},
	isbn = {978-1-4503-2758-9},
	shorttitle = {Twitter {Heron}},
	url = {http://doi.acm.org/10.1145/2723372.2742788},
	doi = {10.1145/2723372.2742788},
	abstract = {Storm has long served as the main platform for real-time analytics at Twitter. However, as the scale of data being processed in real-time at Twitter has increased, along with an increase in the diversity and the number of use cases, many limitations of Storm have become apparent. We need a system that scales better, has better debug-ability, has better performance, and is easier to manage -- all while working in a shared cluster infrastructure. We considered various alternatives to meet these needs, and in the end concluded that we needed to build a new real-time stream data processing system. This paper presents the design and implementation of this new system, called Heron. Heron is now the de facto stream data processing engine inside Twitter, and in this paper we also share our experiences from running Heron in production. In this paper, we also provide empirical evidence demonstrating the efficiency and scalability of Heron.



This article is summarized in:
the morning paper

an interesting/influential/important paper from the world of CS every weekday morning, as selected by Adrian Colyer},
	urldate = {2018-10-08},
	booktitle = {Proceedings of the 2015 {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Kulkarni, Sanjeev and Bhagat, Nikunj and Fu, Maosong and Kedigehalli, Vikas and Kellogg, Christopher and Mittal, Sailesh and Patel, Jignesh M. and Ramasamy, Karthik and Taneja, Siddarth},
	year = {2015},
	keywords = {real-time data processing., stream data processing systems},
	pages = {239--250},
	file = {ACM Full Text PDF:C\:\\Users\\Beni\\Zotero\\storage\\L4PZP3G9\\Kulkarni et al. - 2015 - Twitter Heron Stream Processing at Scale.pdf:application/pdf}
}

@incollection{rasmussen2004gaussian,
  title={Gaussian processes in machine learning},
  author={Rasmussen, Carl Edward},
  booktitle={Advanced lectures on machine learning},
  pages={63--71},
  year={2004},
  publisher={Springer}
}

@inproceedings{schneider_elastic_2009,
	title = {Elastic scaling of data parallel operators in stream processing},
	doi = {10.1109/IPDPS.2009.5161036},
	abstract = {We describe an approach to elastically scale the performance of a data analytics operator that is part of a streaming application. Our techniques focus on dynamically adjusting the amount of computation an operator can carry out in response to changes in incoming workload and the availability of processing cycles. We show that our elastic approach is beneficial in light of the dynamic aspects of streaming workloads and stream processing environments. Addressing another recent trend, we show the importance of our approach as a means to providing computational elasticity in multicore processor-based environments such that operators can automatically find their best operating point. Finally, we present experiments driven by synthetic workloads, showing the space where the optimizing efforts are most beneficial and a radioastronomy imaging application, where we observe substantial improvements in its performance-critical section.},
	booktitle = {2009 {IEEE} {International} {Symposium} on {Parallel} {Distributed} {Processing}},
	author = {Schneider, S. and Andrade, H. and Gedik, B. and Biem, A. and Wu, K. L.},
	month = may,
	year = {2009},
	keywords = {elastic scaling, parallel processing, Intelligent sensors, Multicore processing, multiprocessing systems, Runtime, Streaming media, Elasticity, Application software, Availability, computational elasticity, Computer science, Data analysis, data analytics operator, data parallel operator, media streaming, multicore processor, Performance analysis, radioastronomy imaging, stream processing environment, workload streaming},
	pages = {1--12},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Beni\\Zotero\\storage\\D4L9K7AL\\5161036.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Beni\\Zotero\\storage\\I5XCFJYR\\Schneider et al. - 2009 - Elastic scaling of data parallel operators in stre.pdf:application/pdf}
}

@misc{noauthor_get_nodate,
	title = {{GET} statuses/sample — {Twitter} {Developers}},
	url = {https://developer.twitter.com/en/docs/tweets/sample-realtime/overview/GET_statuse_sample},
	urldate = {2018-10-09},
	file = {GET statuses/sample — Twitter Developers:C\:\\Users\\Beni\\Zotero\\storage\\S2BT2KTA\\GET_statuse_sample.html:text/html}
}

@misc{noauthor_welcome_nodate,
	title = {Welcome to {JGraphT} - a free {Java} {Graph} {Library}},
	url = {https://jgrapht.org/},
	urldate = {2018-10-08},
	file = {Welcome to JGraphT - a free Java Graph Library:C\:\\Users\\Beni\\Zotero\\storage\\9YUNI8UE\\jgrapht.org.html:text/html}
}

@misc{noauthor_smile_nodate,
	title = {Smile - {Statistical} {Machine} {Intelligence} and {Learning} {Engine}},
	url = {http://haifengl.github.io/smile/},
	urldate = {2018-10-08},
	file = {Smile - Statistical Machine Intelligence and Learning Engine:C\:\\Users\\Beni\\Zotero\\storage\\VJT7SYAE\\smile.html:text/html}
}


@misc{noauthor_how_2017,
	title = {How much is 1\%?},
	url = {https://twittercommunity.com/t/how-much-is-1/95878},
	abstract = {Hello,  I haven’t found any clear answer regarding the 1\% limit for the streaming API.  I understand that when extracting real-time tweets from the Streaming API, we are allowed to 1\% of all the tweets “at any given time”.  I dont understand “at any given time”.  For example I extracted 100 000 tweets within 1 hour duration (from 6 to 7 )using the Streaming API. Does this means that during 6 to 7pm, 10 000 000 tweets were tweeted to twitter and so i extracted only 1\%?  thank you},
	language = {en},
	urldate = {2018-10-09},
	journal = {Twitter Developers},
	month = nov,
	year = {2017},
	file = {Snapshot:C\:\\Users\\Beni\\Zotero\\storage\\GWJ5H9TC\\95878.html:text/html}
}

@inproceedings{balkesen_adaptive_2013,
	address = {New York, NY, USA},
	series = {{DEBS} '13},
	title = {Adaptive {Input} {Admission} and {Management} for {Parallel} {Stream} {Processing}},
	isbn = {978-1-4503-1758-0},
	url = {http://doi.acm.org/10.1145/2488222.2488258},
	doi = {10.1145/2488222.2488258},
	abstract = {In this paper, we propose a framework for adaptive admission control and management of a large number of dynamic input streams in parallel stream processing engines. The framework takes as input any available information about input stream behaviors and the requirements of the query processing layer, and adaptively decides how to adjust the entry points of streams to the system. As the optimization decisions propagate early from input management layer to the query processing layer, the size of the cluster is minimized, the load balance is maintained, and latency bounds of queries are met in a more effective and timely manner. Declarative integration of external meta-data about data sources makes the system more robust and resource-efficient. Additionally, exploiting knowledge about queries moves data partitioning to the input management layer, where better load balance for query processing can be achieved. We implemented these techniques as a part of the Borealis stream processing system and conducted experiments showing the performance benefits of our framework.},
	urldate = {2018-06-06},
	booktitle = {Proceedings of the 7th {ACM} {International} {Conference} on {Distributed} {Event}-based {Systems}},
	publisher = {ACM},
	author = {Balkesen, Cagri and Tatbul, Nesime and Özsu, M. Tamer},
	year = {2013},
	keywords = {data streams, adaptive admission control, parallelism},
	pages = {15--26},
	file = {ACM Full Text PDF:C\:\\Users\\Beni\\Zotero\\storage\\LUUM4GPA\\Balkesen et al. - 2013 - Adaptive Input Admission and Management for Parall.pdf:application/pdf}
}

@inproceedings{ying_xing_dynamic_2005,
	address = {Tokyo, Japan},
	title = {Dynamic {Load} {Distribution} in the {Borealis} {Stream} {Processor}},
	isbn = {978-0-7695-2285-2},
	url = {http://ieeexplore.ieee.org/document/1410193/},
	doi = {10.1109/ICDE.2005.53},
	abstract = {Distributed and parallel computing environments are becoming cheap and commonplace. The availability of large numbers of CPU’s makes it possible to process more data at higher speeds. Stream-processing systems are also becoming more important, as broad classes of applications require results in real-time.},
	language = {en},
	urldate = {2018-10-13},
	booktitle = {21st {International} {Conference} on {Data} {Engineering} ({ICDE}'05)},
	publisher = {IEEE},
	author = {{Ying Xing} and Zdonik, S. and {Jeong-Hyon Hwang}},
	year = {2005},
	pages = {791--802},
	file = {Ying Xing et al. - 2005 - Dynamic Load Distribution in the Borealis Stream P.pdf:C\:\\Users\\Beni\\Zotero\\storage\\ZPVISM3U\\Ying Xing et al. - 2005 - Dynamic Load Distribution in the Borealis Stream P.pdf:application/pdf}
}

@inproceedings{heinze_latency-aware_2014,
	title = {Latency-aware elastic scaling for distributed data stream processing systems},
	isbn = {978-1-4503-2737-4},
	url = {http://dl.acm.org/citation.cfm?doid=2611286.2611294},
	doi = {10.1145/2611286.2611294},
	abstract = {Elastic scaling allows a data stream processing system to react to a dynamically changing query or event workload by automatically scaling in or out. Thereby, both unpredictable load peaks as well as underload situations can be handled. However, each scaling decision comes with a latency penalty due to the required operator movements. Therefore, in practice an elastic system might be able to improve the system utilization, however it is not able to provide latency guarantees deﬁned by a service level agreement (SLA).},
	language = {en},
	urldate = {2018-04-27},
	publisher = {ACM Press},
	author = {Heinze, Thomas and Jerzak, Zbigniew and Hackenbroich, Gregor and Fetzer, Christof},
	year = {2014},
	keywords = {lit\_done, Theorie, Placement, vertical},
	pages = {13--22},
	file = {Heinze et al. - 2014 - Latency-aware elastic scaling for distributed data.pdf:C\:\\Users\\Beni\\Zotero\\storage\\YMGVFT9Y\\Heinze et al. - 2014 - Latency-aware elastic scaling for distributed data.pdf:application/pdf}
}

@article{sattler_towards_2013,
	title = {Towards {Elastic} {Stream} {Processing}: {Patterns} and {Infrastructure}.},
	volume = {1018},
	journal = {BD3@ VLDB},
	author = {Sattler, Kai-Uwe and Beier, Felix},
	year = {2013},
	keywords = {Elastizität, Basic, Theorie},
	pages = {49--54},
	file = {Cormode - c 2013 for the individual papers by the papers’ au.pdf:C\:\\Users\\Beni\\Zotero\\storage\\AX9937U9\\Cormode - c 2013 for the individual papers by the papers’ au.pdf:application/pdf}
}

@inproceedings{cugola_tesla:_2010,
	address = {Cambridge, United Kingdom},
	title = {{TESLA}: a formally defined event specification language},
	isbn = {978-1-60558-927-5},
	shorttitle = {{TESLA}},
	url = {http://portal.acm.org/citation.cfm?doid=1827418.1827427},
	doi = {10.1145/1827418.1827427},
	abstract = {The need for timely processing large amounts of information, ﬂowing from the peripheral to the center of a system, is common to diﬀerent application domains, and it has justiﬁed the development of several languages to describe how such information has to be processed. In this paper, we analyze such languages showing how most approaches lack the expressiveness required for the applications we target, or do not provide the precise semantics required to clearly state how the system should behave. Moving from these premises, we present TESLA, a complex event speciﬁcation language. Each TESLA rule considers incoming data items as notiﬁcations of events and deﬁnes how certain patterns of events cause the occurrence of others, said to be “complex”. TESLA has a simple syntax and a formal semantics, given in terms of a ﬁrst order, metric temporal logic. It provides high expressiveness and ﬂexibility in a rigorous framework, by oﬀering content and temporal ﬁlters, negations, timers, aggregates, and fully customizable policies for event selection and consumption. The paper ends by showing how TESLA rules can be interpreted by a processing system, introducing an eﬃcient event detection algorithm based on automata.},
	language = {en},
	urldate = {2018-10-13},
	booktitle = {Proceedings of the {Fourth} {ACM} {International} {Conference} on {Distributed} {Event}-{Based} {Systems} - {DEBS} '10},
	publisher = {ACM Press},
	author = {Cugola, Gianpaolo and Margara, Alessandro},
	year = {2010},
	pages = {50},
	file = {Cugola und Margara - 2010 - TESLA a formally defined event specification lang.pdf:C\:\\Users\\Beni\\Zotero\\storage\\5EA732K7\\Cugola und Margara - 2010 - TESLA a formally defined event specification lang.pdf:application/pdf}
}

@article{cugola_complex_2012,
	title = {Complex event processing with {T}-{REX}},
	volume = {85},
	issn = {01641212},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0164121212000842},
	doi = {10.1016/j.jss.2012.03.056},
	abstract = {Several application domains involve detecting complex situations and reacting to them. This asks for a Complex Event Processing (CEP) middleware speciﬁcally designed to timely process large amounts of event notiﬁcations as they ﬂow from the peripheral to the center of the system, to identify the composite events relevant for the application. To answer this need we designed T-Rex, a new CEP middleware that combines expressiveness and efﬁciency. On the one hand, it adopts a language (TESLA) explicitly conceived to easily and naturally describe composite events. On the other hand, it provides an efﬁcient event detection algorithm based on automata to interpret TESLA rules. Our evaluation shows that the T-Rex engine can process a large number of complex rules with a reduced overhead, even in the presence of challenging workloads.},
	language = {en},
	number = {8},
	urldate = {2018-10-13},
	journal = {Journal of Systems and Software},
	author = {Cugola, Gianpaolo and Margara, Alessandro},
	month = aug,
	year = {2012},
	pages = {1709--1728},
	file = {Cugola und Margara - 2012 - Complex event processing with T-REX.pdf:C\:\\Users\\Beni\\Zotero\\storage\\8BTLREN8\\Cugola und Margara - 2012 - Complex event processing with T-REX.pdf:application/pdf}
}

@misc{noauthor_home_nodate,
	title = {Home page},
	url = {http://www.espertech.com/},
	abstract = {Esper (Java) and NEsper (.net) are open-source software products for Complex Event Processing (CEP), Streaming Analytics and Streaming SQL that analyze series of events for deriving conclusions.},
	language = {en-US},
	urldate = {2018-10-13},
	journal = {EsperTech},
	file = {Snapshot:C\:\\Users\\Beni\\Zotero\\storage\\LYYFEERW\\www.espertech.com.html:text/html}
}

@Comment{jabref-meta: databaseType:biblatex;}
