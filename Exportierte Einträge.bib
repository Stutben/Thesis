
@inproceedings{lohrmann_elastic_2015,
	title = {Elastic {Stream} {Processing} with {Latency} {Guarantees}},
	isbn = {978-1-4673-7214-5},
	url = {http://ieeexplore.ieee.org/document/7164926/},
	doi = {10.1109/ICDCS.2015.48},
	abstract = {Many Big Data applications in science and industry have arisen, that require large amounts of streamed or event data to be analyzed with low latency. This paper presents a reactive strategy to enforce latency guarantees in data ﬂows running on scalable Stream Processing Engines (SPEs), while minimizing resource consumption. We introduce a model for estimating the latency of a data ﬂow, when the degrees of parallelism of the tasks within are changed. We describe how to continuously measure the necessary performance metrics for the model, and how it can be used to enforce latency guarantees, by determining appropriate scaling actions at runtime. Therefore, it leverages the elasticity inherent to common cloud technology and cluster resource management systems. We have implemented our strategy as part of the Nephele SPE. To showcase the effectiveness of our approach, we provide an experimental evaluation on a large commodity cluster, using both a synthetic workload as well as an application performing real-time sentiment analysis on real-world social media data.},
	language = {en},
	urldate = {2018-04-18},
	publisher = {IEEE},
	author = {Lohrmann, Bjorn and Janacik, Peter and Kao, Odej},
	month = jun,
	year = {2015},
	pages = {399--410},
	file = {Lohrmann et al. - 2015 - Elastic Stream Processing with Latency Guarantees.pdf:C\:\\Users\\Beni\\Zotero\\storage\\85S2Q37E\\Lohrmann et al. - 2015 - Elastic Stream Processing with Latency Guarantees.pdf:application/pdf}
}